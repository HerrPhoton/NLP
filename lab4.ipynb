{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 18:02:24.559688: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-03 18:02:24.585604: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-03 18:02:24.585626: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-03 18:02:24.585643: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-03 18:02:24.590472: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-03 18:02:25.120360: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to /home/sanya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from transformers import (MBartForConditionalGeneration, \n",
    "                          MBartTokenizer, \n",
    "                          DataCollatorForSeq2Seq,\n",
    "                          MT5ForConditionalGeneration,\n",
    "                          MT5Tokenizer,\n",
    "                          Seq2SeqTrainingArguments,\n",
    "                          Seq2SeqTrainer)\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры Bart токенайзера\n",
    "MAX_LENGTH = 600\n",
    "PADDING = 'max_length'\n",
    "TRUNCATION = True\n",
    "RETURN_TENSORS = 'pt'\n",
    "\n",
    "# Параметры Bart\n",
    "BART_MODEL_NAME = \"IlyaGusev/mbart_ru_sum_gazeta\"\n",
    "NO_REPEAT_NGRAM = 4\n",
    "\n",
    "# Параметры T5 токенайзера\n",
    "MAX_TARGET_TOKENS_COUNT = 128\n",
    "MAX_SOURCE_TOKENS_COUNT = 1024\n",
    "\n",
    "# Параметры T5\n",
    "T5_MODEL_NAME = \"google/mt5-small\"\n",
    "OUTPUT_DIR = \"T5\"\n",
    "EVALUATION_STRATEGY = \"steps\"\n",
    "EVAL_STEPS = 25\n",
    "LOGGING_STEPS = 25\n",
    "LEARNING_RATE = 4e-4\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 2\n",
    "PER_DEVICE_EVAL_BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = 64\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_TOTAL_LIMIT = 3\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "FP16 = False\n",
    "PREDICT_WITH_GENERATE = True\n",
    "GENERATION_MAX_LENGTH = MAX_TARGET_TOKENS_COUNT\n",
    "GENERATION_NUM_BEAMS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Устройство для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('IlyaGusev/gazeta')\n",
    "\n",
    "# Обрезка датасета, чтобы на GPU влезло\n",
    "dataset['train'] = dataset['train'].select(np.random.choice(range(len(dataset['train'])), size = 200))\n",
    "dataset['test'] = dataset['test'].select(np.random.choice(range(len(dataset['test'])), size = 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Европейские и американские лошади неоднократно...</td>\n",
       "      <td>Неоднократная миграция и скрещивание европейск...</td>\n",
       "      <td>Ученые выяснили детали древнего скрещивания ев...</td>\n",
       "      <td>2021-05-19 14:23:38</td>\n",
       "      <td>https://www.gazeta.ru/science/2021/05/19_a_135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Основатель Telegram-канала NEXTA Роман Протасе...</td>\n",
       "      <td>Задержанный в Минске основатель Telegram-канал...</td>\n",
       "      <td>Протасевич признал вину и рассказал о подготов...</td>\n",
       "      <td>2021-06-03 23:26:11</td>\n",
       "      <td>https://www.gazeta.ru/politics/2021/06/03_a_13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Администрация WhatsApp опубликовала статью, в ...</td>\n",
       "      <td>WhatsApp отреагировал на критику своей обновле...</td>\n",
       "      <td>WhatsApp объяснил передачу личных данных польз...</td>\n",
       "      <td>2021-01-12 14:47:06</td>\n",
       "      <td>https://www.gazeta.ru/tech/2021/01/12/13432892...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Остатки вирусных частиц SARS-CoV-2, осевшие в ...</td>\n",
       "      <td>Остатки коронавируса в кишечнике запускают эво...</td>\n",
       "      <td>Ученые выяснили, как остатки SARS-CoV-2 в кише...</td>\n",
       "      <td>2021-01-22 14:07:16</td>\n",
       "      <td>https://www.gazeta.ru/science/2021/01/22_a_134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Недалеко от деревни Гостилицы в Ломоносовском ...</td>\n",
       "      <td>Менее чем в 50 км от Санкт-Петербурга в воздух...</td>\n",
       "      <td>В Ленобласти разбился легкомоторный самолет с ...</td>\n",
       "      <td>2021-01-08 18:40:53</td>\n",
       "      <td>https://www.gazeta.ru/social/2021/01/08/134295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>В преддверии Дня космонавтики Минобороны опубл...</td>\n",
       "      <td>К 60-летию первого полета человека в космос Ми...</td>\n",
       "      <td>Минобороны опубликовало документы о первых кос...</td>\n",
       "      <td>2021-04-10 00:01:40</td>\n",
       "      <td>https://www.gazeta.ru/science/2021/04/09_a_135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Крымское управление ФСБ сообщило об аресте на ...</td>\n",
       "      <td>Подозреваемый в шпионаже в пользу Украины росс...</td>\n",
       "      <td>Суд в Севастополе арестовал россиянина за госи...</td>\n",
       "      <td>2021-04-22 14:34:57</td>\n",
       "      <td>https://www.gazeta.ru/social/2021/04/22/135686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Очная встреча президентов России и Украины дол...</td>\n",
       "      <td>Владимир Зеленский призвал Владимира Путина вс...</td>\n",
       "      <td>Зеленский пригласил Путина встретиться в Донба...</td>\n",
       "      <td>2021-04-21 11:19:13</td>\n",
       "      <td>https://www.gazeta.ru/politics/2021/04/21_a_13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>В Туве, Ингушетии и Кабардино-Балкарии по итог...</td>\n",
       "      <td>В июне «РИА Рейтинг» назвал Туву, Ингушению и ...</td>\n",
       "      <td>Минтруд назвал регионы с наибольшим уровнем бе...</td>\n",
       "      <td>2021-08-24 16:49:26</td>\n",
       "      <td>https://www.gazeta.ru/social/2021/08/24/139095...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Следственный комитет Белоруссии направил Польш...</td>\n",
       "      <td>Минск требует у Варшавы экстрадировать основат...</td>\n",
       "      <td>Минск направил Варшаве требование выдать основ...</td>\n",
       "      <td>2021-02-07 14:53:17</td>\n",
       "      <td>https://www.gazeta.ru/politics/2021/02/07_a_13...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Европейские и американские лошади неоднократно...   \n",
       "1    Основатель Telegram-канала NEXTA Роман Протасе...   \n",
       "2    Администрация WhatsApp опубликовала статью, в ...   \n",
       "3    Остатки вирусных частиц SARS-CoV-2, осевшие в ...   \n",
       "4    Недалеко от деревни Гостилицы в Ломоносовском ...   \n",
       "..                                                 ...   \n",
       "495  В преддверии Дня космонавтики Минобороны опубл...   \n",
       "496  Крымское управление ФСБ сообщило об аресте на ...   \n",
       "497  Очная встреча президентов России и Украины дол...   \n",
       "498  В Туве, Ингушетии и Кабардино-Балкарии по итог...   \n",
       "499  Следственный комитет Белоруссии направил Польш...   \n",
       "\n",
       "                                               summary  \\\n",
       "0    Неоднократная миграция и скрещивание европейск...   \n",
       "1    Задержанный в Минске основатель Telegram-канал...   \n",
       "2    WhatsApp отреагировал на критику своей обновле...   \n",
       "3    Остатки коронавируса в кишечнике запускают эво...   \n",
       "4    Менее чем в 50 км от Санкт-Петербурга в воздух...   \n",
       "..                                                 ...   \n",
       "495  К 60-летию первого полета человека в космос Ми...   \n",
       "496  Подозреваемый в шпионаже в пользу Украины росс...   \n",
       "497  Владимир Зеленский призвал Владимира Путина вс...   \n",
       "498  В июне «РИА Рейтинг» назвал Туву, Ингушению и ...   \n",
       "499  Минск требует у Варшавы экстрадировать основат...   \n",
       "\n",
       "                                                 title                 date  \\\n",
       "0    Ученые выяснили детали древнего скрещивания ев...  2021-05-19 14:23:38   \n",
       "1    Протасевич признал вину и рассказал о подготов...  2021-06-03 23:26:11   \n",
       "2    WhatsApp объяснил передачу личных данных польз...  2021-01-12 14:47:06   \n",
       "3    Ученые выяснили, как остатки SARS-CoV-2 в кише...  2021-01-22 14:07:16   \n",
       "4    В Ленобласти разбился легкомоторный самолет с ...  2021-01-08 18:40:53   \n",
       "..                                                 ...                  ...   \n",
       "495  Минобороны опубликовало документы о первых кос...  2021-04-10 00:01:40   \n",
       "496  Суд в Севастополе арестовал россиянина за госи...  2021-04-22 14:34:57   \n",
       "497  Зеленский пригласил Путина встретиться в Донба...  2021-04-21 11:19:13   \n",
       "498  Минтруд назвал регионы с наибольшим уровнем бе...  2021-08-24 16:49:26   \n",
       "499  Минск направил Варшаве требование выдать основ...  2021-02-07 14:53:17   \n",
       "\n",
       "                                                   url  \n",
       "0    https://www.gazeta.ru/science/2021/05/19_a_135...  \n",
       "1    https://www.gazeta.ru/politics/2021/06/03_a_13...  \n",
       "2    https://www.gazeta.ru/tech/2021/01/12/13432892...  \n",
       "3    https://www.gazeta.ru/science/2021/01/22_a_134...  \n",
       "4    https://www.gazeta.ru/social/2021/01/08/134295...  \n",
       "..                                                 ...  \n",
       "495  https://www.gazeta.ru/science/2021/04/09_a_135...  \n",
       "496  https://www.gazeta.ru/social/2021/04/22/135686...  \n",
       "497  https://www.gazeta.ru/politics/2021/04/21_a_13...  \n",
       "498  https://www.gazeta.ru/social/2021/08/24/139095...  \n",
       "499  https://www.gazeta.ru/politics/2021/02/07_a_13...  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['test'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_tokenizer = MBartTokenizer.from_pretrained(BART_MODEL_NAME)\n",
    "bart_model = MBartForConditionalGeneration.from_pretrained(BART_MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Тестирование: 100%|██████████| 500/500 [07:39<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "predicts = []\n",
    "\n",
    "for text in tqdm(dataset['test']['text'], desc = 'Тестирование'):\n",
    "\n",
    "    input_ids = bart_tokenizer(text, \n",
    "                               max_length = MAX_LENGTH,\n",
    "                               padding = PADDING,\n",
    "                               truncation = TRUNCATION,\n",
    "                               return_tensors = RETURN_TENSORS)\n",
    "    \n",
    "    input_ids = input_ids['input_ids'].to(device)\n",
    "    \n",
    "    output_ids = bart_model.generate(input_ids = input_ids,\n",
    "                                     no_repeat_ngram_size = NO_REPEAT_NGRAM)\n",
    "    \n",
    "    output_ids = output_ids[0]\n",
    "\n",
    "    predicts.append(bart_tokenizer.decode(output_ids, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Екатеринбургская епархия в исполнение решения суда прибыла на территорию Среднеурального женского монастыря, который ранее «захватил» бывший схимонах Сергий. Представители РПЦ вместе с приставами и экспертами хотели провести экспертизу с целью установления права собственности на монастырский комплекс.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['summary'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Представители епархии Екатеринбурга вместе с вооруженными судебными приставами прибыли в Среднеуральский женский монастырь, где укрывается отлученный от церкви экс-схимонах Сергий (в миру — Николай Романов). Сначала прихожане пытались воспрепятствовать проходу представителей епархии, но после переговоров согласились впустить на территорию монастыря как минимум эксперта. В епархии отметили, что земельные участки, входящие в комплекс монастыря, предоставлены епархии для осуществления религиозной деятельности.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_res = rouge.compute(predictions = predicts,\n",
    "                          references = df['summary'].values)\n",
    "\n",
    "bleu_res = bleu.compute(predictions = predicts,\n",
    "                        references = df['summary'].values)\n",
    "\n",
    "rouge_res = {key: val * 100 for key, val in rouge_res.items()}\n",
    "bleu_res['bleu'] = bleu_res['bleu'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge: {'rouge1': 21.89023286654867, 'rouge2': 8.238439664910253, 'rougeL': 21.3783841304894, 'rougeLsum': 21.207524384799942}\n",
      "Bleu = 8.96%\n"
     ]
    }
   ],
   "source": [
    "print(f'Rouge: {rouge_res}')\n",
    "print(f'Bleu = {bleu_res[\"bleu\"]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "metrics.update(rouge_res)\n",
    "metrics['bleu'] = bleu_res[\"bleu\"]\n",
    "\n",
    "with open('bart_metrics', 'wb') as file:\n",
    "    pickle.dump(metrics, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "t5_model = MT5ForConditionalGeneration.from_pretrained(T5_MODEL_NAME)\n",
    "t5_tokenizer = MT5Tokenizer.from_pretrained(T5_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "   \n",
    "    inputs = examples['text']\n",
    "\n",
    "    model_inputs = t5_tokenizer(inputs, \n",
    "                                max_length = MAX_SOURCE_TOKENS_COUNT, \n",
    "                                truncation = True)\n",
    "    \n",
    "    labels = t5_tokenizer(text_target = examples['summary'], \n",
    "                          max_length = MAX_TARGET_TOKENS_COUNT,\n",
    "                          truncation = True)\n",
    "    \n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8355c44e5f240399bf5f94789540f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Токенезация:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a92534379449f7bf16b3154bd6b4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Токенезация:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess, batched = True, desc = 'Токенезация')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer = t5_tokenizer, model = t5_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    predictions = np.where(predictions != -100, predictions, t5_tokenizer.pad_token_id)\n",
    "    labels = np.where(labels != -100, labels, t5_tokenizer.pad_token_id)\n",
    "\n",
    "    decoded_preds = t5_tokenizer.batch_decode(predictions, skip_special_tokens = True)\n",
    "    decoded_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens = True)\n",
    "\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    result = {}\n",
    "    result_rouge = rouge.compute(predictions = decoded_preds, references = decoded_labels)\n",
    "\n",
    "    # Extract a few results\n",
    "    result.update({key: value * 100 for key, value in result_rouge.items()})\n",
    "\n",
    "    result_bleu = bleu.compute(predictions = decoded_preds, references = decoded_labels)\n",
    "\n",
    "    # Extract a few results\n",
    "    result[\"bleu\"] = result_bleu[\"bleu\"] * 100\n",
    "\n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != t5_tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result[\"char_len\"] = np.mean([len(t) for t in decoded_preds])\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir = OUTPUT_DIR,\n",
    "    evaluation_strategy = EVALUATION_STRATEGY,\n",
    "    eval_steps = EVAL_STEPS,\n",
    "    logging_steps = LOGGING_STEPS,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    per_device_train_batch_size = PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size = PER_DEVICE_EVAL_BATCH_SIZE,\n",
    "    gradient_accumulation_steps = GRADIENT_ACCUMULATION_STEPS,\n",
    "    weight_decay = WEIGHT_DECAY,\n",
    "    save_total_limit = SAVE_TOTAL_LIMIT,\n",
    "    num_train_epochs = NUM_TRAIN_EPOCHS,\n",
    "    fp16 = FP16,\n",
    "    predict_with_generate = PREDICT_WITH_GENERATE,\n",
    "    generation_max_length = GENERATION_MAX_LENGTH,\n",
    "    generation_num_beams = GENERATION_NUM_BEAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model = t5_model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_dataset[\"train\"],\n",
    "    eval_dataset = tokenized_dataset[\"test\"],\n",
    "    tokenizer = t5_tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0ccf938f8f4711a51c0a010275a790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 11.1739, 'train_samples_per_second': 17.899, 'train_steps_per_second': 0.089, 'train_loss': 21.997058868408203, 'epoch': 0.64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1, training_loss=21.997058868408203, metrics={'train_runtime': 11.1739, 'train_samples_per_second': 17.899, 'train_steps_per_second': 0.089, 'train_loss': 21.997058868408203, 'epoch': 0.64})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b148becabe4a61b1b1549a377f2fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 12.623726844787598,\n",
       " 'eval_rouge1': 1.0751,\n",
       " 'eval_rouge2': 0.2461,\n",
       " 'eval_rougeL': 1.0408,\n",
       " 'eval_rougeLsum': 1.0559,\n",
       " 'eval_bleu': 0.0471,\n",
       " 'eval_gen_len': 13.936,\n",
       " 'eval_char_len': 41.112,\n",
       " 'eval_runtime': 69.5649,\n",
       " 'eval_samples_per_second': 7.188,\n",
       " 'eval_steps_per_second': 1.797,\n",
       " 'epoch': 0.64}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_res = trainer.evaluate()\n",
    "eval_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "metrics['rouge1'] = eval_res['eval_rouge1']\n",
    "metrics['rouge2'] = eval_res['eval_rouge2']\n",
    "metrics['rougeL'] = eval_res['eval_rougeL']\n",
    "metrics['rougeLsum'] = eval_res['eval_rougeLsum']\n",
    "metrics['bleu'] = eval_res['eval_bleu']\n",
    "\n",
    "with open('t5_metrics', 'wb') as file:\n",
    "    pickle.dump(metrics, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение метрик Bert и T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bart_metrics', 'rb') as file:\n",
    "    metrics.append(pickle.load(file))\n",
    "\n",
    "with open('t5_metrics', 'rb') as file:\n",
    "    metrics.append(pickle.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bart</th>\n",
       "      <td>21.890233</td>\n",
       "      <td>8.23844</td>\n",
       "      <td>21.378384</td>\n",
       "      <td>21.207524</td>\n",
       "      <td>8.96383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T5</th>\n",
       "      <td>1.075100</td>\n",
       "      <td>0.24610</td>\n",
       "      <td>1.040800</td>\n",
       "      <td>1.055900</td>\n",
       "      <td>0.04710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rouge1   rouge2     rougeL  rougeLsum     bleu\n",
       "Bart  21.890233  8.23844  21.378384  21.207524  8.96383\n",
       "T5     1.075100  0.24610   1.040800   1.055900  0.04710"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(metrics, index = ['Bart', 'T5'])\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
