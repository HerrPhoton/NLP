{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sanya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAAnsCvpJOvsUiObwWTngpvIAQAAAACAAAAAAAQZgAAAAEAACAAAADGgpXwuNNO/c+AA1flG7lurZkwaK5S2UP5mMA28hYE1gAAAAAOgAAAAAIAACAAAABnhpZBclSnxxbpp0Su8hMad0nYRErZlTEIusqZgzndbWAAAABihjy2qnGDjytmsyiuzpM3IZs9EqQfE0ymhFWkxGtGRl/u8BTSBQJK0ZXHMPTzIaTWpYWtT2DjRvGMXVlsd5bWzzy8Xetk7AAe/t0CoCO/o9Vx0d3+lJ0/j+seGx5MmZAAAAAx1fbrX7kTaeS5HdRx+cCnBqzphYVR8+Ib56zQ/DvGsixAdC+CjD9q/vhWHLuGbau9Pya9mxmpSVyfxAbdlVmaw==')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('file'), WindowsPath('/c%3A/Users/Sanya/.vscode/extensions/ms-ceintl.vscode-language-pack-ru-1.84.2023111509/translations/extensions/vscode.markdown-language-features.i18n.json')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/matplotlib_inline.backend_inline'), WindowsPath('module')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=121, Highest Compute Capability: 8.6.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Loading binary c:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda121.so...\n",
      "argument of type 'WindowsPath' is not iterable\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://github.com/TimDettmers/bitsandbytes/blob/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.trainer_seq2seq because of the following error (look up to see its traceback):\n\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\import_utils.py:1345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[0;32m   1346\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer_seq2seq.py:25\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mintegrations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdeepspeed\u001b[39;00m \u001b[39mimport\u001b[39;00m is_deepspeed_zero3_enabled\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:190\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m is_peft_available():\n\u001b[1;32m--> 190\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpeft\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftModel\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m is_accelerate_available():\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.6.2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     AutoPeftModel,\n\u001b[0;32m     24\u001b[0m     AutoPeftModelForCausalLM,\n\u001b[0;32m     25\u001b[0m     AutoPeftModelForSequenceClassification,\n\u001b[0;32m     26\u001b[0m     AutoPeftModelForSeq2SeqLM,\n\u001b[0;32m     27\u001b[0m     AutoPeftModelForTokenClassification,\n\u001b[0;32m     28\u001b[0m     AutoPeftModelForQuestionAnswering,\n\u001b[0;32m     29\u001b[0m     AutoPeftModelForFeatureExtraction,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmapping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001b[0;32m     33\u001b[0m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     inject_adapter_in_model,\n\u001b[0;32m     37\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\auto.py:31\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftConfig\n\u001b[1;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmapping\u001b[39;00m \u001b[39mimport\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     PeftModel,\n\u001b[0;32m     34\u001b[0m     PeftModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     PeftModelForTokenClassification,\n\u001b[0;32m     40\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\mapping.py:23\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftConfig\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     PeftModel,\n\u001b[0;32m     25\u001b[0m     PeftModelForCausalLM,\n\u001b[0;32m     26\u001b[0m     PeftModelForFeatureExtraction,\n\u001b[0;32m     27\u001b[0m     PeftModelForQuestionAnswering,\n\u001b[0;32m     28\u001b[0m     PeftModelForSeq2SeqLM,\n\u001b[0;32m     29\u001b[0m     PeftModelForSequenceClassification,\n\u001b[0;32m     30\u001b[0m     PeftModelForTokenClassification,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtuners\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     AdaLoraConfig,\n\u001b[0;32m     34\u001b[0m     AdaLoraModel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     PromptTuningConfig,\n\u001b[0;32m     48\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\peft_model.py:39\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftConfig\n\u001b[1;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtuners\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     AdaLoraModel,\n\u001b[0;32m     41\u001b[0m     AdaptionPromptModel,\n\u001b[0;32m     42\u001b[0m     IA3Model,\n\u001b[0;32m     43\u001b[0m     LoHaModel,\n\u001b[0;32m     44\u001b[0m     LoKrModel,\n\u001b[0;32m     45\u001b[0m     LoraModel,\n\u001b[0;32m     46\u001b[0m     MultitaskPromptEmbedding,\n\u001b[0;32m     47\u001b[0m     PrefixEncoder,\n\u001b[0;32m     48\u001b[0m     PromptEmbedding,\n\u001b[0;32m     49\u001b[0m     PromptEncoder,\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     52\u001b[0m     SAFETENSORS_WEIGHTS_NAME,\n\u001b[0;32m     53\u001b[0m     TRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     shift_tokens_right,\n\u001b[0;32m     67\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\tuners\\__init__.py:21\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madaption_prompt\u001b[39;00m \u001b[39mimport\u001b[39;00m AdaptionPromptConfig, AdaptionPromptModel\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlora\u001b[39;00m \u001b[39mimport\u001b[39;00m LoraConfig, LoraModel\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mloha\u001b[39;00m \u001b[39mimport\u001b[39;00m LoHaConfig, LoHaModel\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\tuners\\lora\\__init__.py:21\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlayer\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2d, Embedding, Linear, LoraLayer\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m LoraModel\n\u001b[0;32m     24\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mLoraConfig\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mConv2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mEmbedding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLoraLayer\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLinear\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLoraModel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mQuantLinear\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\peft\\tuners\\lora\\model.py:45\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m is_bnb_available():\n\u001b[1;32m---> 45\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbnb\u001b[39;00m \u001b[39mimport\u001b[39;00m Linear8bitLt\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     MatmulLtState,\n\u001b[0;32m      9\u001b[0m     bmm_cublas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     matmul_4bit\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\research\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     switchback_bnb,\n\u001b[0;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[0;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\research\\nn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\research\\nn\\modules.py:8\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mimport\u001b[39;00m GlobalOptimManager\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\optim\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madagrad\u001b[39;00m \u001b[39mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\cextension.py:20\u001b[0m\n\u001b[0;32m     19\u001b[0m     CUDASetup\u001b[39m.\u001b[39mget_instance()\u001b[39m.\u001b[39mprint_log_stack()\n\u001b[1;32m---> 20\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'''\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[39m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001b[39m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[39m    python -m bitsandbytes\u001b[39m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[39m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[39m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[39m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[39m'''\u001b[39m)\n\u001b[0;32m     28\u001b[0m lib\u001b[39m.\u001b[39mcadam32bit_grad_fp32 \u001b[39m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\My_Files\\NSU\\3 Course\\NLP\\lab4\\lab4.ipynb Ячейка 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mpunkt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m (MBartForConditionalGeneration, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                           MBartTokenizer, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                           DataCollatorForSeq2Seq,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                           MT5ForConditionalGeneration,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                           MT5Tokenizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                           pipeline,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                           Seq2SeqTrainingArguments,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                           Seq2SeqTrainer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\import_utils.py:1335\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[0;32m   1334\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m-> 1335\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[0;32m   1336\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1337\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\import_utils.py:1347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1345\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m   1346\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1347\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1348\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1349\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1350\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.trainer_seq2seq because of the following error (look up to see its traceback):\n\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from transformers import (MBartForConditionalGeneration, \n",
    "                          MBartTokenizer, \n",
    "                          DataCollatorForSeq2Seq,\n",
    "                          MT5ForConditionalGeneration,\n",
    "                          MT5Tokenizer,\n",
    "                          pipeline,\n",
    "                          Seq2SeqTrainingArguments,\n",
    "                          Seq2SeqTrainer)\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры Bart токенайзера\n",
    "MAX_LENGTH = 600\n",
    "PADDING = 'max_length'\n",
    "TRUNCATION = True\n",
    "RETURN_TENSORS = 'pt'\n",
    "\n",
    "# Параметры Bart\n",
    "NO_REPEAT_NGRAM = 4\n",
    "\n",
    "# Параметры T5 токенайзера\n",
    "MAX_TARGET_TOKENS_COUNT = 128\n",
    "MAX_SOURCE_TOKENS_COUNT = 1024\n",
    "\n",
    "# Параметры T5\n",
    "OUTPUT_DIR = \"/T5\",\n",
    "EVALUATION_STRATEGY = \"steps\",\n",
    "EVAL_STEPS = 25,\n",
    "LOGGING_STEPS = 25,\n",
    "LEARNING_RATE = 4e-4,\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE = 4,\n",
    "PER_DEVICE_EVAL_BATCH_SIZE = 4,\n",
    "GRADIENT_ACCUMULATION_STEPS = 64,\n",
    "WEIGHT_DECAY = 0.01,\n",
    "SAVE_TOTAL_LIMIT = 3,\n",
    "NUM_TRAIN_EPOCHS = 1,\n",
    "FP16 = False,\n",
    "PREDICT_WITH_GENERATE = True,\n",
    "GENERATION_MAX_LENGTH = MAX_TARGET_TOKENS_COUNT,\n",
    "GENERATION_NUM_BEAMS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Устройство для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('IlyaGusev/gazeta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>На этих выходных в Берлине прошли крупные акци...</td>\n",
       "      <td>Протестующие против антикоронавирусных мер нем...</td>\n",
       "      <td>В Германии объяснили упоминание имени Путина н...</td>\n",
       "      <td>2020-09-01 00:22:59</td>\n",
       "      <td>https://www.gazeta.ru/politics/2020/08/31_a_13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Высокопоставленная американская и израильская ...</td>\n",
       "      <td>Делегации Израиля и США прилетели в ОАЭ, где о...</td>\n",
       "      <td>Делегации Израиля и США прибыли в ОАЭ для обсу...</td>\n",
       "      <td>2020-09-01 08:08:16</td>\n",
       "      <td>https://www.gazeta.ru/politics/2020/08/31_a_13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Одна из руководителей Координационного совета ...</td>\n",
       "      <td>Белорусская оппозиция в лице экс-кандидата в п...</td>\n",
       "      <td>Оппозиция Белоруссии объявила о создании новой...</td>\n",
       "      <td>2020-09-01 09:21:38</td>\n",
       "      <td>https://www.gazeta.ru/politics/2020/09/01_a_13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Россия считает действия ВС США во время учений...</td>\n",
       "      <td>Действия американских ВС в Эстонии во время уч...</td>\n",
       "      <td>Россия считает крайне опасными действия США на...</td>\n",
       "      <td>2020-09-01 09:33:30</td>\n",
       "      <td>https://www.gazeta.ru/army/2020/09/01/13222904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>С 1 сентября в России вступают в силу поправки...</td>\n",
       "      <td>Поправки в российский закон «О банкротстве» вс...</td>\n",
       "      <td>В России вступил в силу закон о внесудебном ба...</td>\n",
       "      <td>2020-09-01 09:49:24</td>\n",
       "      <td>https://www.gazeta.ru/business/2020/09/01/1322...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6788</th>\n",
       "      <td>Феерическим взрывом в атмосфере закончился пер...</td>\n",
       "      <td>Первый пуск американской частной ракеты Alpha ...</td>\n",
       "      <td>СМИ назвали успехом запуск частной ракеты Alph...</td>\n",
       "      <td>2021-09-03 09:28:34</td>\n",
       "      <td>https://www.gazeta.ru/science/2021/09/03_a_139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6789</th>\n",
       "      <td>Глава Минвостокразвития Алексей Чекунков 31 ав...</td>\n",
       "      <td>Городская агломерация Владивостока может дости...</td>\n",
       "      <td>На ВЭФ подписано соглашение о создании города ...</td>\n",
       "      <td>2021-09-03 09:45:36</td>\n",
       "      <td>https://www.gazeta.ru/economics/2021/09/03/139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6790</th>\n",
       "      <td>После взрывов во Врбетице отношения между Чехи...</td>\n",
       "      <td>Из-за геополитической и экономической роли Рос...</td>\n",
       "      <td>Глава чешского МИДа призвал восстанавливать св...</td>\n",
       "      <td>2021-09-03 10:44:03</td>\n",
       "      <td>https://www.gazeta.ru/politics/2021/09/03_a_13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6791</th>\n",
       "      <td>Астрономы впервые наблюдали процесс вспышки св...</td>\n",
       "      <td>Международная группа астрономов впервые наблюд...</td>\n",
       "      <td>Астрономы наблюдали вспышку сверхновой нового ...</td>\n",
       "      <td>2021-09-03 11:43:50</td>\n",
       "      <td>https://www.gazeta.ru/science/2021/09/03_a_139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6792</th>\n",
       "      <td>Москва никогда не отказывалась обсуждать с Ток...</td>\n",
       "      <td>Токио пока не дал гарантий Москве, что не стан...</td>\n",
       "      <td>Путин объяснил, что мешает заключению мира с Я...</td>\n",
       "      <td>2021-09-03 11:50:27</td>\n",
       "      <td>https://www.gazeta.ru/politics/2021/09/03_a_13...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6793 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     На этих выходных в Берлине прошли крупные акци...   \n",
       "1     Высокопоставленная американская и израильская ...   \n",
       "2     Одна из руководителей Координационного совета ...   \n",
       "3     Россия считает действия ВС США во время учений...   \n",
       "4     С 1 сентября в России вступают в силу поправки...   \n",
       "...                                                 ...   \n",
       "6788  Феерическим взрывом в атмосфере закончился пер...   \n",
       "6789  Глава Минвостокразвития Алексей Чекунков 31 ав...   \n",
       "6790  После взрывов во Врбетице отношения между Чехи...   \n",
       "6791  Астрономы впервые наблюдали процесс вспышки св...   \n",
       "6792  Москва никогда не отказывалась обсуждать с Ток...   \n",
       "\n",
       "                                                summary  \\\n",
       "0     Протестующие против антикоронавирусных мер нем...   \n",
       "1     Делегации Израиля и США прилетели в ОАЭ, где о...   \n",
       "2     Белорусская оппозиция в лице экс-кандидата в п...   \n",
       "3     Действия американских ВС в Эстонии во время уч...   \n",
       "4     Поправки в российский закон «О банкротстве» вс...   \n",
       "...                                                 ...   \n",
       "6788  Первый пуск американской частной ракеты Alpha ...   \n",
       "6789  Городская агломерация Владивостока может дости...   \n",
       "6790  Из-за геополитической и экономической роли Рос...   \n",
       "6791  Международная группа астрономов впервые наблюд...   \n",
       "6792  Токио пока не дал гарантий Москве, что не стан...   \n",
       "\n",
       "                                                  title                 date  \\\n",
       "0     В Германии объяснили упоминание имени Путина н...  2020-09-01 00:22:59   \n",
       "1     Делегации Израиля и США прибыли в ОАЭ для обсу...  2020-09-01 08:08:16   \n",
       "2     Оппозиция Белоруссии объявила о создании новой...  2020-09-01 09:21:38   \n",
       "3     Россия считает крайне опасными действия США на...  2020-09-01 09:33:30   \n",
       "4     В России вступил в силу закон о внесудебном ба...  2020-09-01 09:49:24   \n",
       "...                                                 ...                  ...   \n",
       "6788  СМИ назвали успехом запуск частной ракеты Alph...  2021-09-03 09:28:34   \n",
       "6789  На ВЭФ подписано соглашение о создании города ...  2021-09-03 09:45:36   \n",
       "6790  Глава чешского МИДа призвал восстанавливать св...  2021-09-03 10:44:03   \n",
       "6791  Астрономы наблюдали вспышку сверхновой нового ...  2021-09-03 11:43:50   \n",
       "6792  Путин объяснил, что мешает заключению мира с Я...  2021-09-03 11:50:27   \n",
       "\n",
       "                                                    url  \n",
       "0     https://www.gazeta.ru/politics/2020/08/31_a_13...  \n",
       "1     https://www.gazeta.ru/politics/2020/08/31_a_13...  \n",
       "2     https://www.gazeta.ru/politics/2020/09/01_a_13...  \n",
       "3     https://www.gazeta.ru/army/2020/09/01/13222904...  \n",
       "4     https://www.gazeta.ru/business/2020/09/01/1322...  \n",
       "...                                                 ...  \n",
       "6788  https://www.gazeta.ru/science/2021/09/03_a_139...  \n",
       "6789  https://www.gazeta.ru/economics/2021/09/03/139...  \n",
       "6790  https://www.gazeta.ru/politics/2021/09/03_a_13...  \n",
       "6791  https://www.gazeta.ru/science/2021/09/03_a_139...  \n",
       "6792  https://www.gazeta.ru/politics/2021/09/03_a_13...  \n",
       "\n",
       "[6793 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['test'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование Bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"IlyaGusev/mbart_ru_sum_gazeta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MBartTokenizer.from_pretrained(model_name)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6793/6793 [2:12:14<00:00,  1.17s/it]  \n"
     ]
    }
   ],
   "source": [
    "predicts = []\n",
    "\n",
    "for text in tqdm(dataset['test']['text']):\n",
    "\n",
    "    input_ids = tokenizer(text, \n",
    "                          max_length = MAX_LENGTH,\n",
    "                          padding = PADDING,\n",
    "                          truncation = TRUNCATION,\n",
    "                          return_tensors = RETURN_TENSORS)\n",
    "    \n",
    "    input_ids = input_ids['input_ids'].to(device)\n",
    "    \n",
    "    output_ids = model.generate(input_ids = input_ids,\n",
    "                                no_repeat_ngram_size = NO_REPEAT_NGRAM)\n",
    "    \n",
    "    output_ids = output_ids[0]\n",
    "\n",
    "    predicts.append(tokenizer.decode(output_ids, skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Лишний вес при COVID-19 повышает риск столкнуться с осложнениями и оказаться на ИВЛ, предупреждают французские врачи — ожирение наблюдается почти у всех пациентов с коронавирусом, попавших в отделения интенсивной терапии. И чем выше вес, тем выше и вероятность пострадать от тяжелого течения болезни.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['summary'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ожирение повышает риск тяжелого течения COVID-19, предупреждают врачи из Лилльского университета во Франции. По их данным, среди пациентов с лишним весом почти половина страдала от ожирения, у четверти оно было тяжелым.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_res = rouge.compute(predictions = predicts,\n",
    "                          references = df['summary'].values)\n",
    "\n",
    "bleu_res = bleu.compute(predictions = predicts,\n",
    "                        references = df['summary'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge: {'rouge1': 0.2240860568424814, 'rouge2': 0.07871506893854074, 'rougeL': 0.21742531873386722, 'rougeLsum': 0.21767807161655933}\n",
      "Bleu = 0.09\n"
     ]
    }
   ],
   "source": [
    "print(f'Rouge: {rouge_res}')\n",
    "print(f'Bleu = {bleu_res[\"bleu\"]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/mt5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MT5ForConditionalGeneration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\My_Files\\NSU\\3 Course\\NLP\\lab4\\lab4.ipynb Ячейка 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m MT5ForConditionalGeneration\u001b[39m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/My_Files/NSU/3%20Course/NLP/lab4/lab4.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m MT5Tokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_name)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MT5ForConditionalGeneration' is not defined"
     ]
    }
   ],
   "source": [
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = MT5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "   \n",
    "    inputs = examples('text')\n",
    "\n",
    "    model_inputs = tokenizer(inputs, \n",
    "                             max_length = MAX_SOURCE_TOKENS_COUNT, \n",
    "                             truncation = True)\n",
    "    \n",
    "    labels = tokenizer(text_target = examples['summary'], \n",
    "                       max_length = MAX_TARGET_TOKENS_COUNT,\n",
    "                       truncation = True)\n",
    "    \n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(preprocess, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens = True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens = True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = {}\n",
    "    result_rouge = rouge.compute(predictions = decoded_preds, references = decoded_labels)\n",
    "    \n",
    "    # Extract a few results\n",
    "    result.update({key: value.mid.fmeasure * 100 for key, value in result_rouge.items()})\n",
    "    \n",
    "    result_bleu = bleu.compute(predictions = decoded_preds, references = decoded_labels)\n",
    "    \n",
    "    # Extract a few results\n",
    "    result[\"bleu\"] = result_bleu[\"bleu\"] * 100\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result[\"char_len\"] = np.mean([len(t) for t in decoded_preds])\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir = OUTPUT_DIR,\n",
    "    evaluation_strategy = EVALUATION_STRATEGY,\n",
    "    eval_steps = EVAL_STEPS,\n",
    "    logging_steps = LOGGING_STEPS,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    per_device_train_batch_size = PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size = PER_DEVICE_EVAL_BATCH_SIZE,\n",
    "    gradient_accumulation_steps = GRADIENT_ACCUMULATION_STEPS,\n",
    "    weight_decay = WEIGHT_DECAY,\n",
    "    save_total_limit = SAVE_TOTAL_LIMIT,\n",
    "    num_train_epochs = NUM_TRAIN_EPOCHS,\n",
    "    fp16 = FP16,\n",
    "    predict_with_generate = PREDICT_WITH_GENERATE,\n",
    "    generation_max_length = GENERATION_MAX_LENGTH,\n",
    "    generation_num_beams = GENERATION_NUM_BEAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_dataset[\"train\"],\n",
    "    eval_dataset = tokenized_dataset[\"test\"],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение метрик Bart и T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
